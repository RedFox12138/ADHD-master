import os
import sys
import json
from EntropyHub import SampEn
from SampEn import SampEn_optimized
from SingleDenoise import eog_removal
sys.path.append('D:\\anaconda\\lib\\site-packages')
import threading
import collections
from flask import Flask, request, jsonify
from flask_sock import Sock
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.animation import FuncAnimation
import datetime
import requests
from scipy.signal import spectrogram
from PreProcess import preprocess3,compute_power_ratio
from feature_calculator import calculate_features, calculate_realtime_feature
# from openai import OpenAI
from simple_websocket import ConnectionClosed

app = Flask(__name__)
app.config['SECRET_KEY'] = 'adhd_eeg_secret_2024'
sock = Sock(app)

APPID = 'wx5a83526f8eca0449'
SECRET = '907a464400ff1dcf21c297019e543582'
fs = 250


# åˆå§‹åŒ–é˜¿é‡Œäº‘ç™¾ç‚¼å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼Œä¼˜å…ˆç”¨ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY
# import os
# ai_client = OpenAI(
#     api_key=os.getenv("DASHSCOPE_API_KEY", "sk-341c8f4ad671494c84d12201dc2737cf"),
#     base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
# )

user_sessions = {}
session_lock = threading.Lock()
processed_raw_buffer = collections.deque(maxlen=1500)
processed_processed_buffer = collections.deque(maxlen=1500)
hex_buffers = {}  # æ¯ä¸ªç”¨æˆ·çš„16è¿›åˆ¶å­—ç¬¦ä¸²ç¼“å†²åŒº
user_websockets = {}  # ç”¨æˆ·IDåˆ°WebSocketè¿æ¥çš„æ˜ å°„ {user_id: ws}


def process_calibration_data(user_id, trials):
    """
    å¤„ç†ç¦»çº¿å®éªŒæ ‡å®šæ•°æ®ï¼Œåˆ¤æ–­ç”¨æˆ·ç±»å‹
    
    å‚æ•°:
        user_id: ç”¨æˆ·ID
        trials: å®éªŒæ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªtrialåŒ…å«restingDataå’ŒattentionData
    
    è¿”å›:
        {
            'success': bool,
            'user_type': 'type_A' or 'type_B',
            'resting_mean': float,
            'attention_mean': float,
            'description': str
        }
    """
    try:
        print(f'[æ ‡å®š] å¼€å§‹å¤„ç†ç”¨æˆ· {user_id} çš„æ ‡å®šæ•°æ®ï¼Œå…± {len(trials)} æ¬¡å®éªŒ')
        
        # æ”¶é›†æ‰€æœ‰é™æ¯å’Œæ³¨æ„åŠ›é˜¶æ®µçš„ç‰¹å¾å€¼
        all_resting_features = []
        all_attention_features = []
        
        for i, trial in enumerate(trials):
            print(f'[æ ‡å®š] å¤„ç†ç¬¬ {i+1} æ¬¡å®éªŒ')
            
            resting_data = trial.get('restingData', [[]])[0]  # è·å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆæ•°æ®åˆ—è¡¨ï¼‰
            attention_data = trial.get('attentionData', [[]])[0]
            
            # è®¡ç®—é™æ¯é˜¶æ®µçš„ç‰¹å¾ï¼ˆè¿™é‡Œä½¿ç”¨æ ·æœ¬ç†µä½œä¸ºç¤ºä¾‹ï¼‰
            if len(resting_data) > 0:
                # å‡è®¾æ•°æ®æ˜¯åŸå§‹EEGå€¼ï¼Œéœ€è¦å…ˆé¢„å¤„ç†
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨ä½ çš„é¢„å¤„ç†å‡½æ•°
                try:
                    # è®¡ç®—æ ·æœ¬ç†µï¼ˆå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å‚æ•°ï¼‰
                    resting_sampen = calculate_sampen_from_raw(resting_data)
                    all_resting_features.append(resting_sampen)
                    print(f'[æ ‡å®š] å®éªŒ{i+1} é™æ¯æ ·æœ¬ç†µ: {resting_sampen:.4f}')
                except Exception as e:
                    print(f'[æ ‡å®š] å®éªŒ{i+1} é™æ¯æ•°æ®å¤„ç†å¤±è´¥: {e}')
            
            # è®¡ç®—æ³¨æ„åŠ›é˜¶æ®µçš„ç‰¹å¾
            if len(attention_data) > 0:
                try:
                    attention_sampen = calculate_sampen_from_raw(attention_data)
                    all_attention_features.append(attention_sampen)
                    print(f'[æ ‡å®š] å®éªŒ{i+1} æ³¨æ„åŠ›æ ·æœ¬ç†µ: {attention_sampen:.4f}')
                except Exception as e:
                    print(f'[æ ‡å®š] å®éªŒ{i+1} æ³¨æ„åŠ›æ•°æ®å¤„ç†å¤±è´¥: {e}')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®
        if len(all_resting_features) < 2 or len(all_attention_features) < 2:
            return {
                'success': False,
                'message': f'æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘2æ¬¡æœ‰æ•ˆå®éªŒã€‚å½“å‰é™æ¯: {len(all_resting_features)}, æ³¨æ„åŠ›: {len(all_attention_features)}'
            }
        
        # è®¡ç®—å‡å€¼
        resting_mean = np.mean(all_resting_features)
        attention_mean = np.mean(all_attention_features)
        
        print(f'[æ ‡å®š] é™æ¯å‡å€¼: {resting_mean:.4f}, æ³¨æ„åŠ›å‡å€¼: {attention_mean:.4f}')
        
        # åˆ¤æ–­ç”¨æˆ·ç±»å‹
        if resting_mean > attention_mean:
            user_type = 'type_A'
            description = 'é™æ¯æ—¶æ ·æœ¬ç†µ > æ³¨æ„åŠ›æ—¶æ ·æœ¬ç†µ'
        else:
            user_type = 'type_B'
            description = 'é™æ¯æ—¶æ ·æœ¬ç†µ < æ³¨æ„åŠ›æ—¶æ ·æœ¬ç†µ'
        
        print(f'[æ ‡å®š] ç”¨æˆ·ç±»å‹: {user_type} ({description})')
        
        return {
            'success': True,
            'user_type': user_type,
            'resting_mean': float(resting_mean),
            'attention_mean': float(attention_mean),
            'description': description,
            'resting_features': [float(f) for f in all_resting_features],
            'attention_features': [float(f) for f in all_attention_features]
        }
        
    except Exception as e:
        print(f'[æ ‡å®š] å¤„ç†å¤±è´¥: {e}')
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'message': str(e)
        }


def calculate_sampen_from_raw(raw_data):
    """
    ä»åŸå§‹æ•°æ®è®¡ç®—ç‰¹å¾ï¼ˆä½¿ç”¨å…¨å±€ç‰¹å¾è®¡ç®—æ¨¡å—ï¼‰
    
    å‚æ•°:
        raw_data: åŸå§‹EEGæ•°æ®åˆ—è¡¨ï¼ˆ16è¿›åˆ¶å­—ç¬¦ä¸²æˆ–æ•°å€¼ï¼‰
    
    è¿”å›:
        ç‰¹å¾å€¼
    """
    # å¦‚æœæ•°æ®æ˜¯16è¿›åˆ¶å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œéœ€è¦å…ˆè½¬æ¢
    if isinstance(raw_data[0], str):
        # è½¬æ¢16è¿›åˆ¶å­—ç¬¦ä¸²ä¸ºæ•´æ•°
        eeg_values = []
        for hex_str in raw_data:
            try:
                # å‡è®¾æ¯10ä¸ªå­—ç¬¦æ˜¯ä¸€ä¸ªæ•°æ®åŒ…
                for i in range(0, len(hex_str), 10):
                    packet = hex_str[i:i+10]
                    if len(packet) == 10:
                        # æå–EEGå€¼ï¼ˆæ ¹æ®ä½ çš„æ•°æ®æ ¼å¼è°ƒæ•´ï¼‰
                        eeg_hex = packet[0:6]
                        value = int(eeg_hex, 16)
                        # è½¬æ¢ä¸ºæœ‰ç¬¦å·æ•°
                        if value > 0x7FFFFF:
                            value -= 0x1000000
                        eeg_values.append(value)
            except Exception as e:
                continue
    else:
        eeg_values = raw_data
    
    # é¢„å¤„ç†ï¼šå»é™¤åŸºçº¿æ¼‚ç§»ç­‰
    if len(eeg_values) > 100:
        eeg_array = np.array(eeg_values, dtype=float)
        
        # ç®€å•çš„å»å‡å€¼å¤„ç†
        eeg_array = eeg_array - np.mean(eeg_array)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ç‰¹å¾è®¡ç®—æ¥å£
        try:
            feature_value = calculate_features(eeg_array, fs=250)
            return feature_value
        except Exception as e:
            print(f'[ç‰¹å¾è®¡ç®—] è®¡ç®—å¤±è´¥: {e}')
            # é™çº§ä½¿ç”¨ç®€å•ç»Ÿè®¡ç‰¹å¾
            return np.std(eeg_array)
    else:
        return 0.0


def get_user_session(user_id):
    current_time = datetime.datetime.now()
    date_str = current_time.strftime("%Y%m%d")  # æŒ‰æ—¥æœŸç»„ç»‡æ•°æ®

    # åˆ›å»ºæŒ‰æ—¥æœŸç»„ç»‡çš„ç›®å½•ç»“æ„ - ç»Ÿä¸€ä½¿ç”¨ eeg_data å’Œ eeg_results
    user_dir = os.path.join('data', user_id, 'eeg_data', date_str)
    result_dir = os.path.join('data', user_id, 'eeg_results', date_str)

    with session_lock:
        os.makedirs(user_dir, exist_ok=True)
        os.makedirs(result_dir, exist_ok=True)

        if user_id not in user_sessions or \
                (current_time - user_sessions[user_id]['last_time']).total_seconds() > 10:
            timestamp = current_time.strftime("%H%M%S_%f")[:-3]
            user_sessions[user_id] = {
                'last_time': current_time,
                'date': date_str,
                'raw_file': os.path.join(user_dir, f"raw_{timestamp}.txt"),
                'Delta_result': os.path.join(result_dir, f"{timestamp}.txt"),
                'processed_file': os.path.join(user_dir, f"processed_{timestamp}.txt"),
                'processing_buffer': [],
                'delta_cumavg_history': [],
                'tbr_base_list': [],
                'Base_value': None,
                'Base_flag': False,
                'feature_buffer': [],  # ç¼“å­˜4ä¸ª0.5sçª—å£çš„ç‰¹å¾å€¼
                'push_counter': 0,     # æ¨é€è®¡æ•°å™¨
                'difficulty_saved': False,  # éš¾åº¦ä¿¡æ¯ä¿å­˜æ ‡å¿—
                'recording': False,  # æ•°æ®è®°å½•æ§åˆ¶æ ‡å¿—
                'recording_started': False  # æ˜¯å¦å·²ç»å¼€å§‹è¿‡è®°å½•ï¼ˆç”¨äºåˆ›å»ºæ–°æ–‡ä»¶ï¼‰
            }
        else:
            user_sessions[user_id]['last_time'] = current_time

        return user_sessions[user_id]['raw_file'], user_sessions[user_id]['processed_file'], user_sessions[user_id][
            'Delta_result']


def calculate_delta_cumavg(eeg_data, Step,fs=250, session=None):
    """è®¡ç®—Deltaæ³¢æ®µçš„æ»‘åŠ¨çª—å£ç´¯ç§¯å¹³å‡åŠŸç‡ï¼ˆ6ç§’çª—å£ï¼Œ0.5ç§’æ­¥é•¿ï¼‰"""
    # è®¾ç½®STFTå‚æ•°
    window = "hamming"
    nfft = 1024
    # è®¡ç®—STFT
    f, t, S = spectrogram(np.array(eeg_data), fs=fs, window=window, nperseg=512, noverlap=256, nfft=nfft, mode='magnitude')
    # å®šä¹‰Deltaæ³¢æ®µèŒƒå›´
    delta_band = (f >= 0.5) & (f <= 4)  # Delta: 0.5-4Hz
    # æå–Deltaæ³¢æ®µåŠŸç‡ï¼ˆå¹…åº¦å¹³æ–¹ï¼‰
    S_delta = np.abs(S[delta_band, :]) ** 2
    # è®¡ç®—Deltaæ³¢æ®µç¬æ—¶åŠŸç‡ï¼ˆè·¨é¢‘ç‡ç»´åº¦å¹³å‡ï¼‰
    delta_power = np.mean(S_delta, axis=0)
    # è®¡ç®—å½“å‰çª—å£çš„å¹³å‡åŠŸç‡
    current_window_avg = np.mean(delta_power) if len(delta_power) > 0 else None
    # æ›´æ–°ä¼šè¯ä¸­çš„ç´¯ç§¯å¹³å‡å†å²
    if current_window_avg is not None and session is not None:
        if Step == 'åŸºå‡†é˜¶æ®µ':
            session['delta_cumavg_history'].append(current_window_avg)
            cumulative_avg = np.mean(session['delta_cumavg_history'][-5:])  # çœŸæ­£çš„ç´¯ç§¯å¹³å‡
            return cumulative_avg
        elif Step == 'æ²»ç–—é˜¶æ®µ':
            return current_window_avg
    return None

def decode_hex_data(hex_string, user_id):
    """
    è§£ç 16è¿›åˆ¶å­—ç¬¦ä¸²ä¸ºEEGæ•°æ®ç‚¹ï¼ˆæ”¯æŒè·¨æ‰¹æ¬¡çš„ä¸å®Œæ•´æ•°æ®åŒ…ï¼‰
    
    é€»è¾‘ï¼š
    1. æ¯ä¸ªæ•°æ®åŒ…é•¿åº¦ä¸º10ä¸ªå­—ç¬¦ï¼ˆ5å­—èŠ‚ï¼‰
    2. æ•°æ®åŒ…æ ¼å¼ï¼šå¤´éƒ¨2å­—ç¬¦(11) + æ•°æ®6å­—ç¬¦ + å°¾éƒ¨2å­—ç¬¦(01)
    3. å¤´éƒ¨å¿…é¡»æ˜¯'11'ï¼Œå°¾éƒ¨å¿…é¡»æ˜¯'01'
    4. ä¸­é—´6ä¸ªå­—ç¬¦æ˜¯24ä½æœ‰ç¬¦å·æ•´æ•°çš„16è¿›åˆ¶è¡¨ç¤º
    5. è½¬æ¢å…¬å¼ï¼švalue = int(hex_str, 16) * 2.24 * 1000 / 8388608
    6. å¦‚æœå€¼ >= 8388608 (0x800000)ï¼Œéœ€è¦å‡å» 16777216 (0x1000000) æ¥å¾—åˆ°è´Ÿæ•°
    
    å‚æ•°ï¼š
        hex_string: 16è¿›åˆ¶å­—ç¬¦ä¸²
        user_id: ç”¨æˆ·IDï¼Œç”¨äºç®¡ç†ç”¨æˆ·ç¼“å†²åŒº
    
    è¿”å›ï¼š
        decoded_data: è§£ç åçš„æ•°æ®ç‚¹åˆ—è¡¨
    """
    global hex_buffers
    
    # ä»ç”¨æˆ·ç¼“å†²åŒºè·å–ä¸Šæ¬¡æœªå¤„ç†å®Œçš„æ•°æ®
    if user_id not in hex_buffers:
        hex_buffers[user_id] = ''
    
    # æ‹¼æ¥ä¸Šæ¬¡å‰©ä½™çš„æ•°æ®
    full_hex = hex_buffers[user_id] + hex_string
    
    decoded_data = []
    packet_length = 10
    i = 0
    
    while i + packet_length <= len(full_hex):
        # æ£€æŸ¥æ•°æ®åŒ…æ ¼å¼ï¼šå¤´éƒ¨'11'ï¼Œå°¾éƒ¨'01'
        if (full_hex[i:i+2] == '11' and 
            full_hex[i+8:i+10] == '01'):
            
            # æå–ä¸­é—´6ä¸ªå­—ç¬¦ï¼ˆ24ä½æ•°æ®ï¼‰
            hex_value = full_hex[i+2:i+8]
            
            try:
                # è½¬æ¢ä¸ºæ•´æ•°
                value = int(hex_value, 16)
                
                # å¤„ç†æœ‰ç¬¦å·æ•°ï¼ˆ24ä½è¡¥ç ï¼‰
                if value >= 8388608:  # 0x800000ï¼Œ24ä½æœ€é«˜ä½ä¸º1è¡¨ç¤ºè´Ÿæ•°
                    value -= 16777216  # 0x1000000ï¼Œè½¬æ¢ä¸ºè´Ÿæ•°
                
                # åº”ç”¨è½¬æ¢å…¬å¼
                value = value * 2.24 * 1000 / 8388608
                
                decoded_data.append(value)
                i += packet_length
            except ValueError:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç§»åŠ¨ä¸€ä¸ªå­—ç¬¦ç»§ç»­
                i += 1
        else:
            # æ ¼å¼ä¸åŒ¹é…ï¼Œç§»åŠ¨ä¸€ä¸ªå­—ç¬¦ç»§ç»­æœç´¢
            i += 1
    
    # ä¿å­˜å‰©ä½™çš„æœªå¤„ç†æ•°æ®åˆ°ç¼“å†²åŒº
    hex_buffers[user_id] = full_hex[i:]
    
    return decoded_data


@app.route('/process', methods=['POST'])
def process_data():
    data = request.json
    hex_data = data.get('hexData', '')  # æ¥æ”¶16è¿›åˆ¶å­—ç¬¦ä¸²
    points = data.get('points', [])      # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šç›´æ¥æ¥æ”¶è§£ç åçš„æ•°æ®
    user_id = data.get('userId')
    Step = data.get('Step')
    difficulty = data.get('difficulty', 'normal')  # æ¥æ”¶éš¾åº¦ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºnormal

    tbr_list = []
    
    # å¦‚æœæ¥æ”¶åˆ°16è¿›åˆ¶æ•°æ®ï¼Œå…ˆè§£ç 
    if hex_data:
        points = decode_hex_data(hex_data, user_id)
    
    # delta_cumavg_list = []

    if not user_id:
        return jsonify({"error": "userId is required"}), 400

    raw_file, processed_file,delta_file= get_user_session(user_id)
    
    # ä¿å­˜éš¾åº¦ä¿¡æ¯åˆ°difficulty.jsonï¼ˆä»…åœ¨æ²»ç–—é˜¶æ®µå¼€å§‹æ—¶ä¿å­˜ä¸€æ¬¡ï¼‰
    if Step == 'æ²»ç–—é˜¶æ®µ':
        with session_lock:
            session = user_sessions[user_id]
            if not session.get('difficulty_saved', False):
                # è·å–ç»“æœç›®å½•è·¯å¾„
                result_dir = os.path.dirname(delta_file)
                difficulty_file = os.path.join(result_dir, 'difficulty.json')
                
                # è¯»å–ç°æœ‰çš„éš¾åº¦ä¿¡æ¯
                difficulties = {}
                if os.path.exists(difficulty_file):
                    try:
                        with open(difficulty_file, 'r', encoding='utf-8') as f:
                            difficulties = json.load(f)
                    except Exception as e:
                        print(f"[éš¾åº¦ä¿¡æ¯] è¯»å–å¤±è´¥: {e}")
                
                # æ·»åŠ å½“å‰æ–‡ä»¶çš„éš¾åº¦ä¿¡æ¯
                file_name = os.path.basename(delta_file)
                difficulties[file_name] = difficulty
                
                # ä¿å­˜éš¾åº¦ä¿¡æ¯
                try:
                    with open(difficulty_file, 'w', encoding='utf-8') as f:
                        json.dump(difficulties, f, ensure_ascii=False, indent=2)
                    print(f"[éš¾åº¦ä¿¡æ¯] ä¿å­˜æˆåŠŸ: {file_name} -> {difficulty}")
                except Exception as e:
                    print(f"[éš¾åº¦ä¿¡æ¯] ä¿å­˜å¤±è´¥: {e}")
                
                session['difficulty_saved'] = True

    # if Step == 'åŸºå‡†é˜¶æ®µ' or Step == 'æ²»ç–—é˜¶æ®µ':
    if True:
        with session_lock:
            session = user_sessions[user_id]
            session['processing_buffer'].extend(points)

        # åªæœ‰åœ¨recordingä¸ºTrueæ—¶æ‰ä¿å­˜åŸå§‹æ•°æ®åˆ°æ–‡ä»¶
        with session_lock:
            session = user_sessions[user_id]
            is_recording = session.get('recording', False)
            is_calibration_recording = session.get('calibration_recording', False)
            calibration_raw_file = session.get('calibration_raw_file')
        
        if is_recording:
            with open(raw_file, 'a') as f:
                for p in points:
                    f.write(f"{p}\n")
                f.flush()
        
        # ç¦»çº¿å®éªŒæœŸé—´åŒæ—¶å†™å…¥ç¦»çº¿å®éªŒæ–‡ä»¶ï¼ˆä¸å¡”é˜²æ¸¸æˆä¸€æ ·ï¼Œå†™å…¥è½¬æ¢åçš„æ•°æ®ï¼‰
        if is_calibration_recording and calibration_raw_file:
            with open(calibration_raw_file, 'a') as f:
                for p in points:
                    f.write(f"{p}\n")
                f.flush()


        with session_lock:
            session = user_sessions[user_id]
            processing_buffer = session['processing_buffer']
        #print(len(processing_buffer))

        while len(processing_buffer) >= 1500: # 6ç§’çª—å£ï¼ˆ1500ç‚¹ï¼‰
            raw_window = processing_buffer[:1500]
            processed_points, _ = preprocess3(raw_window, fs)
            processed_points = eog_removal(processed_points, 250, False)

            # theta_band = [4, 8]
            # beta_band = [13, 30]
            # tbr = compute_power_ratio(processed_points, fs, theta_band, beta_band)

            samp = SampEn_optimized(processed_points)
            tbr = samp[0][2]

            # tbr = 1

            # ========== æ‰€æœ‰é˜¶æ®µéƒ½ç¼“å­˜TBRå¹¶æ¨é€ï¼ˆæ¯2ç§’æ¨é€ä¸€æ¬¡å¹³å‡å€¼ï¼‰ ==========
            session['feature_buffer'].append(tbr)
            session['push_counter'] += 1
            
            # æ¯4ä¸ª0.5sçª—å£ï¼ˆ2ç§’ï¼‰æ¨é€ä¸€æ¬¡å¹³å‡å€¼
            if session['push_counter'] >= 4:
                avg_tbr = np.mean(session['feature_buffer'])
                
                # æ²»ç–—é˜¶æ®µï¼šä¿å­˜å¹³å‡å€¼åˆ°æ–‡ä»¶
                if Step == 'æ²»ç–—é˜¶æ®µ':
                    # æ²»ç–—é˜¶æ®µå¼€å§‹æ—¶ï¼Œä¿å­˜åç«¯è®¡ç®—çš„åŸºå‡†å€¼åˆ°æ–‡ä»¶
                    if session['Base_flag'] == False:
                        with open(delta_file, 'a') as f:
                            f.write(f"{session['Base_value']}\n")
                            f.flush()
                        session['Base_flag'] = True
                    
                    # ä¿å­˜å¹³å‡å€¼åˆ°æ–‡ä»¶ï¼ˆæ¯2ç§’ä¿å­˜ä¸€æ¬¡ï¼‰
                    with open(delta_file, 'a') as f:
                        f.write(f"{avg_tbr}\n")
                        f.flush()
                
                # æ¨é€ç»™å°ç¨‹åºï¼ˆæ‰€æœ‰é˜¶æ®µï¼‰
                if user_id in user_websockets:
                    try:
                        ws = user_websockets[user_id]
                        message_data = {
                            'TBR': avg_tbr,
                            'timestamp': datetime.datetime.now().isoformat(),
                            'Step': Step
                        }
                        ws.send(json.dumps(message_data))
                        # é™é»˜æ¨é€ï¼Œä¸æ‰“å°æ—¥å¿—ï¼ˆé¿å…åˆ·å±ï¼‰
                    except Exception as e:
                        print(f'[æ¨é€] âŒ æ¨é€å¤±è´¥: {e}')
                        # æ¨é€å¤±è´¥ï¼Œå¯èƒ½è¿æ¥å·²æ–­å¼€ï¼Œä»å­—å…¸ä¸­åˆ é™¤
                        if user_id in user_websockets:
                            del user_websockets[user_id]
                            print(f'[æ¨é€] ğŸ”Œ ç”¨æˆ· {user_id} è¿æ¥å·²å¤±æ•ˆï¼Œå·²ç§»é™¤')
                else:
                    # åªåœ¨é¦–æ¬¡å‘ç°ç”¨æˆ·æœªæ³¨å†Œæ—¶æ‰“å°è­¦å‘Š
                    if not hasattr(session, '_warned_unregistered'):
                        print(f'[æ¨é€] âš ï¸ ç”¨æˆ· {user_id} ä¸åœ¨å·²æ³¨å†Œåˆ—è¡¨ä¸­ï¼Œæ— æ³•æ¨é€TBR')
                        print(f'[æ¨é€] ğŸ“Š å½“å‰å·²æ³¨å†Œç”¨æˆ·: {list(user_websockets.keys())}')
                        session['_warned_unregistered'] = True
                
                # æ¸…ç©ºç¼“å†²åŒºå’Œè®¡æ•°å™¨
                session['feature_buffer'] = []
                session['push_counter'] = 0
            # ========== æ¨é€é€»è¾‘ç»“æŸ ==========

            # åç«¯è´Ÿè´£ï¼šç´¯ç§¯è®¡ç®—åŸºå‡†å€¼ï¼ˆç”¨äºä¿å­˜ï¼‰
            # å°ç¨‹åºè´Ÿè´£ï¼šæ”¶é›†æ¨é€çš„æ ·æœ¬ç†µï¼Œæ¸¸æˆå¼€å§‹æ—¶è‡ªå·±è®¡ç®—åŸºå‡†å€¼
            if Step == 'åŸºå‡†é˜¶æ®µ' :
                tbr_list.append(tbr)
                
                # åç«¯ç´¯ç§¯è®¡ç®—åŸºå‡†å€¼ï¼ˆç”¨äºä¿å­˜åˆ°æ–‡ä»¶ï¼‰
                session['tbr_base_list'].append(tbr)
                tbr_cumavg = np.mean(session['tbr_base_list'])
                session['Base_value'] = tbr_cumavg

            elif Step == 'æ²»ç–—é˜¶æ®µ' :
                tbr_list.append(tbr)

            # æ›´æ–°ç»˜å›¾ç¼“å†²åŒº
            processed_raw_buffer.extend(raw_window)
            processed_processed_buffer.extend(processed_points)

            # ç§»åŠ¨çª—å£ï¼ˆ0.5ç§’æ­¥é•¿=125ç‚¹ï¼‰
            with session_lock:
                session['processing_buffer'] = processing_buffer[125:]
                processing_buffer = session['processing_buffer']


        # ä¸å†è¿”å›TBRåˆ—è¡¨ï¼Œæ”¹ä¸ºé€šè¿‡WebSocketæ¨é€
        return jsonify({
            "status": "success",
            "message": "Data received and processing"
        })


# ========== åŸç”ŸWebSocketè¿æ¥å¤„ç†ï¼ˆflask-sockï¼‰==========

@sock.route('/ws')
def websocket(ws):
    """å¤„ç†å¾®ä¿¡å°ç¨‹åºçš„åŸç”ŸWebSocketè¿æ¥"""
    user_id = None
    print('='*50)
    print('[WebSocket] ğŸ”Œ æ–°è¿æ¥å»ºç«‹')
    print('='*50)
    
    try:
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            message = ws.receive()
            if message is None:
                print('[WebSocket] âš ï¸ æ”¶åˆ°ç©ºæ¶ˆæ¯ï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€')
                break
            
            # åªæ‰“å°éå¿ƒè·³æ¶ˆæ¯
            try:
                data = json.loads(message)
                event = data.get('event')
                
                # å¿ƒè·³æ¶ˆæ¯ä¸æ‰“å°
                if event != 'ping':
                    print(f'[WebSocket] ğŸ“© æ”¶åˆ°æ¶ˆæ¯: {message}')
                
                if event == 'register_user':
                    # ç”¨æˆ·æ³¨å†Œ
                    user_id = data.get('userId')
                    if user_id:
                        # å¦‚æœç”¨æˆ·å·²å­˜åœ¨ï¼ˆé‡è¿ï¼‰ï¼Œå…ˆåˆ é™¤æ—§è¿æ¥
                        if user_id in user_websockets:
                            print(f'[WebSocket] ğŸ”„ ç”¨æˆ· {user_id} é‡æ–°è¿æ¥ï¼Œæ›´æ–°WebSocketå¯¹è±¡')
                        
                        user_websockets[user_id] = ws
                        print(f'[WebSocket] âœ… ç”¨æˆ· {user_id} æ³¨å†ŒæˆåŠŸ')
                        print(f'[WebSocket] ğŸ“Š å½“å‰å·²æ³¨å†Œç”¨æˆ·: {list(user_websockets.keys())}')
                        
                        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æ´»è·ƒçš„session
                        has_session = user_id in user_sessions
                        print(f'[WebSocket] ğŸ“‹ ç”¨æˆ· {user_id} æ˜¯å¦æœ‰æ´»è·ƒsession: {has_session}')
                        
                        ws.send(json.dumps({
                            'event': 'registered',
                            'message': f'ç”¨æˆ· {user_id} æ³¨å†ŒæˆåŠŸ',
                            'userId': user_id,
                            'hasSession': has_session
                        }))
                        
                        # å¦‚æœæ²¡æœ‰sessionï¼Œæç¤ºéœ€è¦å‘é€æ•°æ®
                        if not has_session:
                            print(f'[WebSocket] âš ï¸ ç”¨æˆ· {user_id} æ²¡æœ‰æ´»è·ƒsessionï¼Œéœ€è¦å¼€å§‹å‘é€æ•°æ®æ‰èƒ½æ¥æ”¶TBRæ¨é€')
                        else:
                            print(f'[WebSocket] âœ… ç”¨æˆ· {user_id} æœ‰æ´»è·ƒsessionï¼Œç­‰å¾…æ•°æ®å¤„ç†åæ¨é€TBR')
                
                elif event == 'ping':
                    # å¿ƒè·³å“åº”ï¼ˆé™é»˜å¤„ç†ï¼Œä¸æ‰“å°æ—¥å¿—ï¼‰
                    ws.send(json.dumps({'event': 'pong', 'message': 'pong'}))
                    
                elif event == 'start_recording':
                    # å¼€å§‹è®°å½•æ•°æ®
                    user_id = data.get('userId')
                    if user_id:
                        with session_lock:
                            if user_id in user_sessions:
                                session = user_sessions[user_id]
                                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å¼€å§‹è®°å½•ï¼Œåˆ›å»ºæ–°æ–‡ä»¶
                                if not session.get('recording_started', False):
                                    current_time = datetime.datetime.now()
                                    date_str = current_time.strftime("%Y%m%d")
                                    timestamp = current_time.strftime("%H%M%S_%f")[:-3]
                                    
                                    user_dir = os.path.join('data', user_id, 'eeg_data', date_str)
                                    result_dir = os.path.join('data', user_id, 'eeg_results', date_str)
                                    os.makedirs(user_dir, exist_ok=True)
                                    os.makedirs(result_dir, exist_ok=True)
                                    
                                    session['raw_file'] = os.path.join(user_dir, f"raw_{timestamp}.txt")
                                    session['Delta_result'] = os.path.join(result_dir, f"{timestamp}.txt")
                                    session['processed_file'] = os.path.join(user_dir, f"processed_{timestamp}.txt")
                                    session['recording_started'] = True
                                
                                session['recording'] = True
                                print(f'[WebSocket] ğŸ”´ ç”¨æˆ· {user_id} å¼€å§‹è®°å½•æ•°æ® -> {session["raw_file"]}')
                                ws.send(json.dumps({
                                    'event': 'recording_started',
                                    'message': 'å¼€å§‹è®°å½•æ•°æ®',
                                    'userId': user_id
                                }))
                            else:
                                print(f'[WebSocket] âš ï¸ ç”¨æˆ· {user_id} æ²¡æœ‰æ´»è·ƒsessionï¼Œæ— æ³•å¼€å§‹è®°å½•')
                                ws.send(json.dumps({
                                    'event': 'error',
                                    'message': 'æ²¡æœ‰æ´»è·ƒsession'
                                }))
                    
                elif event == 'stop_recording':
                    # åœæ­¢è®°å½•æ•°æ®
                    user_id = data.get('userId')
                    if user_id:
                        with session_lock:
                            if user_id in user_sessions:
                                session = user_sessions[user_id]
                                session['recording'] = False
                                session['recording_started'] = False  # é‡ç½®æ ‡å¿—ï¼Œä¸‹æ¬¡å¼€å§‹æ—¶åˆ›å»ºæ–°æ–‡ä»¶
                                print(f'[WebSocket] â¹ï¸ ç”¨æˆ· {user_id} åœæ­¢è®°å½•æ•°æ®')
                                ws.send(json.dumps({
                                    'event': 'recording_stopped',
                                    'message': 'åœæ­¢è®°å½•æ•°æ®',
                                    'userId': user_id
                                }))
                            else:
                                print(f'[WebSocket] âš ï¸ ç”¨æˆ· {user_id} æ²¡æœ‰æ´»è·ƒsession')
                
                elif event == 'start_calibration_recording':
                    # å¼€å§‹ç¦»çº¿å®éªŒæ•°æ®è®°å½•ï¼ˆå­¦ä¹ å¡”é˜²æ¸¸æˆçš„æ–¹å¼ï¼‰
                    user_id = data.get('userId')
                    trial_number = data.get('trialNumber', 1)
                    if user_id:
                        with session_lock:
                            if user_id in user_sessions:
                                session = user_sessions[user_id]
                                current_time = datetime.datetime.now()
                                timestamp = current_time.strftime("%Y%m%d_%H%M%S")
                                
                                # åˆ›å»ºç¦»çº¿å®éªŒç›®å½•
                                calibration_dir = os.path.join('data', user_id, 'calibration', f'trial_{trial_number}')
                                os.makedirs(calibration_dir, exist_ok=True)
                                
                                session['calibration_raw_file'] = os.path.join(calibration_dir, f"raw_{timestamp}.txt")
                                session['calibration_trial'] = trial_number
                                session['calibration_recording'] = True
                                
                                print(f'[WebSocket] ğŸ”´ ç¦»çº¿å®éªŒ{trial_number} å¼€å§‹è®°å½• -> {session["calibration_raw_file"]}')
                                ws.send(json.dumps({
                                    'event': 'calibration_recording_started',
                                    'message': f'ç¦»çº¿å®éªŒ{trial_number}å¼€å§‹è®°å½•',
                                    'userId': user_id
                                }))
                
                elif event == 'stop_calibration_recording':
                    # åœæ­¢ç¦»çº¿å®éªŒæ•°æ®è®°å½•å¹¶è§¦å‘å¤„ç†
                    user_id = data.get('userId')
                    trial_number = data.get('trialNumber', 1)
                    if user_id:
                        with session_lock:
                            if user_id in user_sessions:
                                session = user_sessions[user_id]
                                session['calibration_recording'] = False
                                raw_file = session.get('calibration_raw_file')
                                
                                print(f'[WebSocket] â¹ï¸ ç¦»çº¿å®éªŒ{trial_number} åœæ­¢è®°å½•')
                                
                                # å¼‚æ­¥å¤„ç†æ•°æ®
                                def process_async():
                                    from calibration_processor import process_calibration_trial, analyze_all_trials
                                    
                                    if raw_file and os.path.exists(raw_file):
                                        result = process_calibration_trial(raw_file, user_id, trial_number, fs=250)
                                        
                                        if result['success']:
                                            print(f'[ç¦»çº¿å®éªŒ] âœ… ç¬¬{trial_number}æ¬¡å®éªŒå¤„ç†å®Œæˆ')
                                            
                                            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å®éªŒéƒ½å®Œæˆ
                                            features_files = [
                                                os.path.join('data', user_id, 'calibration', f'trial_{i}_features.json')
                                                for i in range(1, 3)
                                            ]
                                            
                                            if all(os.path.exists(f) for f in features_files):
                                                print(f'[ç¦»çº¿å®éªŒ] ğŸ¯ æ‰€æœ‰å®éªŒå®Œæˆï¼Œå¼€å§‹æœ€ç»ˆåˆ†æ...')
                                                final_result = analyze_all_trials(user_id, num_trials=2)
                                                
                                                if final_result['success']:
                                                    result_file = os.path.join('data', user_id, 'calibration', 'calibration_result.json')
                                                    with open(result_file, 'w', encoding='utf-8') as f:
                                                        json.dump(final_result, f, ensure_ascii=False, indent=2)
                                                    print(f'[ç¦»çº¿å®éªŒ] âœ… ç”¨æˆ·{user_id}æ ‡å®šå®Œæˆ: {final_result["user_type"]}')
                                
                                threading.Thread(target=process_async).start()
                                
                                ws.send(json.dumps({
                                    'event': 'calibration_recording_stopped',
                                    'message': f'ç¦»çº¿å®éªŒ{trial_number}åœæ­¢è®°å½•ï¼Œå¼€å§‹å¤„ç†',
                                    'userId': user_id
                                }))
                    
                elif event == 'unregister_user':
                    # ç”¨æˆ·æ³¨é”€
                    user_id = data.get('userId')
                    if user_id and user_id in user_websockets:
                        del user_websockets[user_id]
                        print(f'[WebSocket] ğŸ‘‹ ç”¨æˆ· {user_id} å·²æ³¨é”€')
                        ws.send(json.dumps({
                            'event': 'unregistered',
                            'message': f'ç”¨æˆ· {user_id} å·²æ³¨é”€'
                        }))
                
                elif event == 'submit_calibration':
                    # æ¥æ”¶ç¦»çº¿å®éªŒæ ‡å®šæ•°æ®å¹¶è¿›è¡Œåˆ†ç±»
                    print('[WebSocket] ğŸ¯ æ”¶åˆ°ç¦»çº¿å®éªŒæ ‡å®šæ•°æ®')
                    user_id = data.get('user_id')
                    trials = data.get('trials', [])
                    
                    if not user_id or not trials:
                        ws.send(json.dumps({
                            'type': 'error',
                            'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'
                        }))
                    else:
                        # è°ƒç”¨æ ‡å®šæ•°æ®å¤„ç†å‡½æ•°
                        result = process_calibration_data(user_id, trials)
                        
                        if result['success']:
                            # ä¿å­˜æ ‡å®šç»“æœ
                            calibration_dir = os.path.join('data', user_id, 'calibration')
                            os.makedirs(calibration_dir, exist_ok=True)
                            
                            result_file = os.path.join(calibration_dir, 'calibration_result.json')
                            with open(result_file, 'w', encoding='utf-8') as f:
                                json.dump(result, f, ensure_ascii=False, indent=2)
                            
                            print(f'[WebSocket] âœ… ç”¨æˆ· {user_id} æ ‡å®šå®Œæˆ: {result["user_type"]}')
                            
                            # å‘é€ç»“æœåˆ°å°ç¨‹åº
                            ws.send(json.dumps({
                                'type': 'calibration_result',
                                'data': {
                                    'user_type': result['user_type'],
                                    'resting_mean': result['resting_mean'],
                                    'attention_mean': result['attention_mean'],
                                    'description': result.get('description', '')
                                }
                            }))
                        else:
                            ws.send(json.dumps({
                                'type': 'error',
                                'message': result.get('message', 'æ ‡å®šæ•°æ®å¤„ç†å¤±è´¥')
                            }))
                
            except json.JSONDecodeError as e:
                print(f'[WebSocket] âŒ æ¶ˆæ¯æ ¼å¼é”™è¯¯: {e}')
                ws.send(json.dumps({'error': 'æ¶ˆæ¯æ ¼å¼é”™è¯¯'}))
    
    except Exception as e:
        print(f'[WebSocket] âŒ è¿æ¥å¼‚å¸¸: {e}')
        import traceback
        traceback.print_exc()
    
    finally:
        # è¿æ¥æ–­å¼€ï¼Œæ¸…ç†ç”¨æˆ·æ³¨å†Œä¿¡æ¯
        if user_id and user_id in user_websockets:
            del user_websockets[user_id]
            print(f'[WebSocket] ğŸ”Œ ç”¨æˆ· {user_id} è¿æ¥æ–­å¼€')
            print(f'[WebSocket] ğŸ“Š å‰©ä½™ç”¨æˆ·: {list(user_websockets.keys())}')
        else:
            print('[WebSocket] ğŸ”Œ è¿æ¥æ–­å¼€ï¼ˆæœªæ³¨å†Œç”¨æˆ·ï¼‰')

# ========================================

@app.route('/upload_calibration_data', methods=['POST'])
def upload_calibration_data():
    """
    æ¥æ”¶ç¦»çº¿å®éªŒæ•°æ®å¹¶å¤„ç†
    """
    try:
        data = request.json
        user_id = data.get('user_id')
        trial_number = data.get('trial_number', 1)
        eeg_data = data.get('eeg_data', [])  # 80ç§’çš„EEGæ•°æ®æ•°ç»„
        
        if not user_id or not eeg_data:
            return jsonify({'success': False, 'message': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
        
        print(f'[ç¦»çº¿å®éªŒ] æ”¶åˆ°ç”¨æˆ· {user_id} ç¬¬ {trial_number} æ¬¡å®éªŒæ•°æ®ï¼Œå…± {len(eeg_data)} ä¸ªç‚¹')
        
        # åˆ›å»ºç›®å½•
        calibration_dir = os.path.join('data', user_id, 'calibration', f'trial_{trial_number}')
        os.makedirs(calibration_dir, exist_ok=True)
        
        # ä¿å­˜åŸå§‹æ•°æ®
        current_time = datetime.datetime.now()
        timestamp = current_time.strftime("%Y%m%d_%H%M%S")
        raw_file = os.path.join(calibration_dir, f'raw_{timestamp}.txt')
        
        with open(raw_file, 'w') as f:
            for value in eeg_data:
                f.write(f'{value}\n')
        
        print(f'[ç¦»çº¿å®éªŒ] æ•°æ®å·²ä¿å­˜åˆ°: {raw_file}')
        
        # å¯åŠ¨åå°å¤„ç†
        def process_async():
            from calibration_processor import process_calibration_trial, analyze_all_trials
            
            # å¤„ç†å•æ¬¡å®éªŒ
            result = process_calibration_trial(raw_file, user_id, trial_number, fs=250)
            
            if result['success']:
                print(f'[ç¦»çº¿å®éªŒ] âœ… ç¬¬ {trial_number} æ¬¡å®éªŒå¤„ç†å®Œæˆ')
                print(f'[ç¦»çº¿å®éªŒ] ğŸ“ æ•°æ®ä¿å­˜ä½ç½®: data/{user_id}/calibration/')
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å®éªŒéƒ½å®Œæˆï¼ˆå‡è®¾éœ€è¦2æ¬¡ï¼‰
                features_files = [
                    os.path.join('data', user_id, 'calibration', f'trial_{i}_features.json')
                    for i in range(1, 3)
                ]
                
                if all(os.path.exists(f) for f in features_files):
                    print(f'[ç¦»çº¿å®éªŒ] ğŸ¯ æ‰€æœ‰å®éªŒå®Œæˆï¼Œå¼€å§‹æœ€ç»ˆåˆ†æ...')
                    
                    # åˆ†ææ‰€æœ‰å®éªŒ
                    final_result = analyze_all_trials(user_id, num_trials=2)
                    
                    if final_result['success']:
                        result_file = os.path.join('data', user_id, 'calibration', 'calibration_result.json')
                        with open(result_file, 'w', encoding='utf-8') as f:
                            json.dump(final_result, f, ensure_ascii=False, indent=2)
                        
                        print(f'[ç¦»çº¿å®éªŒ] âœ… ç”¨æˆ· {user_id} æ ‡å®šå®Œæˆ: {final_result["user_type"]}')
                        print(f'[ç¦»çº¿å®éªŒ] ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜: {result_file}')
                        
                        # ä¿å­˜è¯¦ç»†çš„åˆ†ææŠ¥å‘Š
                        report_file = os.path.join('data', user_id, 'calibration', 'analysis_report.txt')
                        with open(report_file, 'w', encoding='utf-8') as f:
                            f.write(f"ç”¨æˆ·æ ‡å®šåˆ†ææŠ¥å‘Š\n")
                            f.write(f"=" * 50 + "\n")
                            f.write(f"ç”¨æˆ·ID: {user_id}\n")
                            f.write(f"å®éªŒæ¬¡æ•°: {num_trials}\n")
                            f.write(f"åˆ†ç±»ç»“æœ: {final_result['user_type']}\n")
                            f.write(f"æè¿°: {final_result['description']}\n")
                            f.write(f"\nè¯¦ç»†æ•°æ®:\n")
                            f.write(f"é™æ¯é˜¶æ®µå‡å€¼: {final_result['resting_mean']:.4f}\n")
                            f.write(f"æ³¨æ„åŠ›é˜¶æ®µå‡å€¼: {final_result['attention_mean']:.4f}\n")
                            f.write(f"\nå„æ¬¡å®éªŒæ•°æ®:\n")
                            for i, (r, a) in enumerate(zip(final_result.get('all_resting_means', []), 
                                                          final_result.get('all_attention_means', [])), 1):
                                f.write(f"  å®éªŒ{i}: é™æ¯={r:.4f}, æ³¨æ„åŠ›={a:.4f}\n")
                        print(f'[ç¦»çº¿å®éªŒ] ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}')
            else:
                print(f'[ç¦»çº¿å®éªŒ] âŒ å¤„ç†å¤±è´¥: {result.get("message")}')
        
        # åœ¨åå°çº¿ç¨‹å¤„ç†ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        threading.Thread(target=process_async).start()
        
        # ç«‹å³è¿”å›å“åº”
        return jsonify({
            'success': True,
            'message': f'ç¬¬ {trial_number} æ¬¡å®éªŒæ•°æ®å·²æ¥æ”¶ï¼Œæ­£åœ¨åå°å¤„ç†...',
            'trial_number': trial_number
        })
        
    except Exception as e:
        print(f'[ç¦»çº¿å®éªŒ] âŒ ä¸Šä¼ å¤±è´¥: {e}')
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/get_calibration_result', methods=['GET'])
def get_calibration_result():
    """
    æŸ¥è¯¢ç¦»çº¿å®éªŒçš„å¤„ç†ç»“æœ
    """
    user_id = request.args.get('user_id')
    
    if not user_id:
        return jsonify({'success': False, 'message': 'ç¼ºå°‘user_idå‚æ•°'}), 400
    
    result_file = os.path.join('data', user_id, 'calibration', 'calibration_result.json')
    
    if os.path.exists(result_file):
        with open(result_file, 'r', encoding='utf-8') as f:
            result = json.load(f)
        return jsonify(result)
    else:
        # æ£€æŸ¥å·²å®Œæˆçš„å®éªŒæ•°é‡
        trial_count = 0
        for i in range(1, 3):
            features_file = os.path.join('data', user_id, 'calibration', f'trial_{i}_features.json')
            if os.path.exists(features_file):
                trial_count += 1
        
        return jsonify({
            'success': False,
            'message': 'æ ‡å®šæœªå®Œæˆ',
            'completed_trials': trial_count,
            'required_trials': 2
        })


@app.route('/get_calibration_status', methods=['GET'])
def get_calibration_status():
    """
    è·å–ç”¨æˆ·æ ‡å®šçŠ¶æ€ï¼ˆåŒ…æ‹¬å·²å®Œæˆçš„å®éªŒæ¬¡æ•°å’Œæ ‡å®šç»“æœï¼‰
    ç”¨äºå°ç¨‹åºé‡æ–°æ‰“å¼€æ—¶åŠ è½½ç”¨æˆ·æ•°æ®
    """
    user_id = request.args.get('user_id')
    
    if not user_id:
        return jsonify({'success': False, 'message': 'ç¼ºå°‘user_idå‚æ•°'}), 400
    
    print(f'[æ ‡å®šçŠ¶æ€] æŸ¥è¯¢ç”¨æˆ· {user_id} çš„æ ‡å®šçŠ¶æ€')
    
    # æ£€æŸ¥å·²å®Œæˆçš„å®éªŒæ•°é‡
    trial_count = 0
    for i in range(1, 10):  # æœ€å¤šæ£€æŸ¥10æ¬¡å®éªŒ
        features_file = os.path.join('data', user_id, 'calibration', f'trial_{i}_features.json')
        if os.path.exists(features_file):
            trial_count += 1
        else:
            break  # å¦‚æœæŸæ¬¡ä¸å­˜åœ¨ï¼Œåé¢çš„ä¹Ÿä¸å­˜åœ¨
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆæ ‡å®šç»“æœ
    result_file = os.path.join('data', user_id, 'calibration', 'calibration_result.json')
    calibration_result = None
    
    if os.path.exists(result_file):
        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                calibration_result = json.load(f)
            print(f'[æ ‡å®šçŠ¶æ€] ç”¨æˆ· {user_id} å·²å®Œæˆæ ‡å®š: {calibration_result.get("user_type")}')
        except Exception as e:
            print(f'[æ ‡å®šçŠ¶æ€] è¯»å–æ ‡å®šç»“æœå¤±è´¥: {e}')
    
    response_data = {
        'success': True,
        'user_id': user_id,
        'completed_trials': trial_count,
        'required_trials': 2,
        'calibration_result': calibration_result  # å¯èƒ½ä¸ºNone
    }
    
    print(f'[æ ‡å®šçŠ¶æ€] è¿”å›: å·²å®Œæˆ{trial_count}æ¬¡å®éªŒ, æ ‡å®šç»“æœ={calibration_result is not None}')
    
    return jsonify(response_data)


@app.route('/getOpenId', methods=['POST'])
def get_openid():
    data = request.json
    code = data.get('code')

    if not code:
        return jsonify({"error": "code is required"}), 400

    url = f"https://api.weixin.qq.com/sns/jscode2session?appid={APPID}&secret={SECRET}&js_code={code}&grant_type=authorization_code"
    response = requests.get(url)
    result = response.json()
    if 'openid' in result:
        return jsonify({"openid": result['openid']})
    else:
        return jsonify({"error": "Failed to get openid", "details": result}), 500


def run_flask():
    """è¿è¡ŒFlaskæœåŠ¡å™¨"""
    app.run(host='0.0.0.0', port=5000, debug=False)


def update_plot(frame):
    x = np.arange(len(processed_raw_buffer))
    y_raw = np.array(processed_raw_buffer)
    y_processed = np.array(processed_processed_buffer)

    raw_line.set_data(x, y_raw)
    processed_line.set_data(x, y_processed)

    ax.set_xlim(0, 1500)
    ax.set_ylim(-200, 200)
    return raw_line, processed_line


@app.route('/getHistoryDates', methods=['POST'])
def get_history_dates():
    """
    è·å–ç”¨æˆ·æœ‰å†å²è®°å½•çš„æ—¥æœŸåˆ—è¡¨
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid" }
    è¿”å›: { "success": bool, "dates": [æ—¥æœŸåˆ—è¡¨], "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400

        # ç”¨æˆ·ç»“æœç›®å½•è·¯å¾„
        result_dir = os.path.join('data', user_id, 'result')

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(result_dir):
            return jsonify({"success": True, "dates": []})

        # è·å–æ‰€æœ‰æ—¥æœŸç›®å½•
        dates = []
        for date_dir in os.listdir(result_dir):
            if os.path.isdir(os.path.join(result_dir, date_dir)):
                try:
                    # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆæ—¥æœŸæ ¼å¼ (YYYYMMDD)
                    datetime.datetime.strptime(date_dir, "%Y%m%d")
                    dates.append(date_dir)
                except ValueError:
                    continue

        # æŒ‰æ—¥æœŸé™åºæ’åº
        dates.sort(reverse=True)

        return jsonify({
            "success": True,
            "dates": dates
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/getHistoryFiles', methods=['POST'])
def get_history_files():
    """
    è·å–ç”¨æˆ·ç‰¹å®šæ—¥æœŸçš„å†å²æ–‡ä»¶åˆ—è¡¨
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid", "date": "YYYYMMDD" }
    è¿”å›: { "success": bool, "files": [æ–‡ä»¶ååˆ—è¡¨], "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')
        date = data.get('date')

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400
        if not date:
            return jsonify({"success": False, "error": "date is required"}), 400

        # éªŒè¯æ—¥æœŸæ ¼å¼
        try:
            datetime.datetime.strptime(date, "%Y%m%d")
        except ValueError:
            return jsonify({"success": False, "error": "Invalid date format (should be YYYYMMDD)"}), 400

        # ç”¨æˆ·ç»“æœç›®å½•è·¯å¾„
        result_dir = os.path.join('data', user_id, 'result', date)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(result_dir):
            return jsonify({"success": True, "files": []})

        # è·å–æ‰€æœ‰.txtæ–‡ä»¶å¹¶æŒ‰ä¿®æ”¹æ—¶é—´æ’åº(æœ€æ–°åœ¨å‰)
        files = []
        for f in os.listdir(result_dir):
            if f.endswith('.txt'):
                file_path = os.path.join(result_dir, f)
                files.append({
                    "name": f,
                    "path": file_path,
                    "mtime": os.path.getmtime(file_path)
                })

        # æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åº
        files.sort(key=lambda x: x['mtime'], reverse=True)
        
        # è¯»å–éš¾åº¦ä¿¡æ¯ï¼ˆä»åŒç›®å½•ä¸‹çš„difficulty.jsonæ–‡ä»¶ï¼‰
        difficulties = {}
        difficulty_file = os.path.join(result_dir, 'difficulty.json')
        if os.path.exists(difficulty_file):
            try:
                with open(difficulty_file, 'r', encoding='utf-8') as f:
                    difficulties = json.load(f)
            except Exception as e:
                print(f"[éš¾åº¦ä¿¡æ¯] è¯»å–å¤±è´¥: {e}")

        return jsonify({
            "success": True,
            "files": [f["name"] for f in files],
            "difficulties": difficulties  # æ·»åŠ éš¾åº¦ä¿¡æ¯
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/getHistoryFile', methods=['POST'])
def get_history_file():
    """
    è·å–ç‰¹å®šå†å²æ–‡ä»¶å†…å®¹ï¼ˆç‰¹å¾æ•°æ®ï¼Œä»resultç›®å½•ï¼‰
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid", "date": "YYYYMMDD", "fileName": "æ–‡ä»¶å" }
    è¿”å›: { "success": bool, "data": [æ•°å€¼æ•°ç»„], "baseline": åŸºå‡†å€¼, "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')
        date = data.get('date')
        file_name = data.get('fileName')

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400
        if not date:
            return jsonify({"success": False, "error": "date is required"}), 400
        if not file_name:
            return jsonify({"success": False, "error": "fileName is required"}), 400

        # å®‰å…¨æ£€æŸ¥
        if '../' in file_name or '..\\' in file_name:
            return jsonify({"success": False, "error": "Invalid file name"}), 400

        # æ–‡ä»¶è·¯å¾„
        file_path = os.path.join('data', user_id, 'result', date, file_name)
        
        # è¯»å–éš¾åº¦ä¿¡æ¯
        difficulty = 'normal'  # é»˜è®¤æ™®é€šéš¾åº¦
        difficulty_file = os.path.join('data', user_id, 'result', date, 'difficulty.json')
        if os.path.exists(difficulty_file):
            try:
                with open(difficulty_file, 'r', encoding='utf-8') as f:
                    difficulties = json.load(f)
                    difficulty = difficulties.get(file_name, 'normal')
            except Exception as e:
                print(f"[éš¾åº¦ä¿¡æ¯] è¯»å–å¤±è´¥: {e}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            return jsonify({"success": False, "error": "File not found"}), 404

        # è¯»å–æ–‡ä»¶å†…å®¹å¹¶è§£æä¸ºæ•°å€¼æ•°ç»„
        data_points = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        value = float(line)
                        data_points.append(value)
                    except ValueError:
                        print(f"Warning: æ— æ³•è§£æè¡Œå†…å®¹: {line}")
                        continue

        if not data_points:
            return jsonify({"success": False, "error": "æ–‡ä»¶æ— æœ‰æ•ˆæ•°æ®"}), 400

        # ç¬¬ä¸€ä¸ªå€¼æ˜¯åŸºå‡†å€¼ï¼Œå…¶ä½™æ˜¯æ²»ç–—é˜¶æ®µæ•°æ®
        baseline = data_points[0] if len(data_points) > 0 else None
        treatment_data = data_points[1:] if len(data_points) > 1 else []

        return jsonify({
            "success": True,
            "data": treatment_data,
            "baseline": baseline,
            "totalPoints": len(treatment_data),
            "difficulty": difficulty  # æ·»åŠ éš¾åº¦ä¿¡æ¯
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/getRawHistoryDates', methods=['POST'])
def get_raw_history_dates():
    """
    è·å–ç”¨æˆ·æœ‰åŸå§‹ä¿¡å·è®°å½•çš„æ—¥æœŸåˆ—è¡¨
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid" }
    è¿”å›: { "success": bool, "dates": [æ—¥æœŸåˆ—è¡¨], "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400

        # ç”¨æˆ·åŸå§‹æ•°æ®ç›®å½•è·¯å¾„
        data_dir = os.path.join('data', user_id, 'data')

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(data_dir):
            return jsonify({"success": True, "dates": []})

        # è·å–æ‰€æœ‰æ—¥æœŸç›®å½•
        dates = []
        for date_dir in os.listdir(data_dir):
            if os.path.isdir(os.path.join(data_dir, date_dir)):
                try:
                    # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆæ—¥æœŸæ ¼å¼ (YYYYMMDD)
                    datetime.datetime.strptime(date_dir, "%Y%m%d")
                    dates.append(date_dir)
                except ValueError:
                    continue

        # æŒ‰æ—¥æœŸé™åºæ’åº
        dates.sort(reverse=True)

        return jsonify({
            "success": True,
            "dates": dates
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/getRawHistoryFiles', methods=['POST'])
def get_raw_history_files():
    """
    è·å–ç”¨æˆ·ç‰¹å®šæ—¥æœŸçš„åŸå§‹ä¿¡å·æ–‡ä»¶åˆ—è¡¨
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid", "date": "YYYYMMDD" }
    è¿”å›: { "success": bool, "files": [æ–‡ä»¶ååˆ—è¡¨], "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')
        date = data.get('date')

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400
        if not date:
            return jsonify({"success": False, "error": "date is required"}), 400

        # éªŒè¯æ—¥æœŸæ ¼å¼
        try:
            datetime.datetime.strptime(date, "%Y%m%d")
        except ValueError:
            return jsonify({"success": False, "error": "Invalid date format (should be YYYYMMDD)"}), 400

        # ç”¨æˆ·åŸå§‹æ•°æ®ç›®å½•è·¯å¾„
        data_dir = os.path.join('data', user_id, 'data', date)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(data_dir):
            return jsonify({"success": True, "files": []})

        # è·å–æ‰€æœ‰raw_å¼€å¤´çš„.txtæ–‡ä»¶å¹¶æŒ‰ä¿®æ”¹æ—¶é—´æ’åº(æœ€æ–°åœ¨å‰)
        files = []
        for f in os.listdir(data_dir):
            if f.startswith('raw_') and f.endswith('.txt'):
                file_path = os.path.join(data_dir, f)
                files.append({
                    "name": f,
                    "path": file_path,
                    "mtime": os.path.getmtime(file_path)
                })

        # æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åº
        files.sort(key=lambda x: x['mtime'], reverse=True)

        return jsonify({
            "success": True,
            "files": [f["name"] for f in files]
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/getRawHistoryFile', methods=['POST'])
def get_raw_history_file():
    """
    è·å–ç‰¹å®šåŸå§‹ä¿¡å·æ–‡ä»¶å†…å®¹
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid", "date": "YYYYMMDD", "fileName": "æ–‡ä»¶å", "start": èµ·å§‹ç´¢å¼•, "count": æ•°æ®ç‚¹æ•°é‡ }
    è¿”å›: { "success": bool, "data": [æ•°å€¼æ•°ç»„], "totalPoints": æ€»æ•°æ®ç‚¹æ•°, "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')
        date = data.get('date')
        file_name = data.get('fileName')
        start = data.get('start', 0)  # èµ·å§‹ç´¢å¼•ï¼Œé»˜è®¤0
        count = data.get('count', 10000)  # ä¸€æ¬¡è¯»å–çš„æ•°æ®ç‚¹æ•°ï¼Œé»˜è®¤10000

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400
        if not date:
            return jsonify({"success": False, "error": "date is required"}), 400
        if not file_name:
            return jsonify({"success": False, "error": "fileName is required"}), 400

        # å®‰å…¨æ£€æŸ¥
        if '../' in file_name or '..\\' in file_name:
            return jsonify({"success": False, "error": "Invalid file name"}), 400
        if not file_name.startswith('raw_'):
            return jsonify({"success": False, "error": "Invalid raw file name"}), 400

        # æ–‡ä»¶è·¯å¾„
        file_path = os.path.join('data', user_id, 'data', date, file_name)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            return jsonify({"success": False, "error": "File not found"}), 404

        # è¯»å–æ–‡ä»¶å†…å®¹å¹¶è§£æä¸ºæ•°å€¼æ•°ç»„
        all_data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        value = float(line)
                        all_data.append(value)
                    except ValueError:
                        continue

        if not all_data:
            return jsonify({"success": False, "error": "æ–‡ä»¶æ— æœ‰æ•ˆæ•°æ®"}), 400

        total_points = len(all_data)
        
        # æ ¹æ®startå’Œcountæˆªå–æ•°æ®
        end = min(start + count, total_points)
        data_slice = all_data[start:end]

        return jsonify({
            "success": True,
            "data": data_slice,
            "totalPoints": total_points,
            "start": start,
            "end": end
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/saveGameRecord', methods=['POST'])
def save_game_record():
    """
    ä¿å­˜æ¸¸æˆæ—¶é•¿è®°å½•
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid", "gameTime": æ¸¸æˆæ—¶é•¿(ç§’), "difficulty": "easy/normal/hard" }
    è¿”å›: { "success": bool, "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')
        game_time = data.get('gameTime')
        difficulty = data.get('difficulty', 'normal')  # è·å–éš¾åº¦ï¼Œé»˜è®¤ä¸ºæ™®é€š

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400
        if game_time is None:
            return jsonify({"success": False, "error": "gameTime is required"}), 400

        # ç¡®ä¿game_timeæ˜¯æ•´æ•°
        try:
            game_time = int(game_time)
        except (ValueError, TypeError):
            return jsonify({"success": False, "error": "gameTime must be an integer"}), 400

        # éªŒè¯éš¾åº¦å‚æ•°
        if difficulty not in ['easy', 'normal', 'hard']:
            difficulty = 'normal'

        # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
        now = datetime.datetime.now()
        date_str = now.strftime("%Y%m%d")
        timestamp = now.strftime("%Y-%m-%d %H:%M:%S")

        # æ¸¸æˆè®°å½•ç›®å½•è·¯å¾„
        records_dir = os.path.join('data', user_id, 'game_records')
        os.makedirs(records_dir, exist_ok=True)

        # è®°å½•æ–‡ä»¶è·¯å¾„ï¼ˆæŒ‰æ—¥æœŸå‘½åï¼‰
        record_file = os.path.join(records_dir, f"{date_str}.txt")

        # è¿½åŠ è®°å½•ï¼ˆæ ¼å¼ï¼šæ—¶é—´æˆ³,æ¸¸æˆæ—¶é•¿,éš¾åº¦ï¼‰
        with open(record_file, 'a', encoding='utf-8') as f:
            f.write(f"{timestamp},{game_time},{difficulty}\n")

        print(f"[æ¸¸æˆè®°å½•] ç”¨æˆ· {user_id} æ¸¸æˆæ—¶é•¿ {game_time}ç§’ éš¾åº¦ {difficulty} å·²ä¿å­˜")

        return jsonify({"success": True})

    except Exception as e:
        print(f"[æ¸¸æˆè®°å½•é”™è¯¯] {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

def analyze_training_trend(records):
    """
    åˆ†æè®­ç»ƒå†å²è¶‹åŠ¿å¹¶ç»™å‡ºå»ºè®®
    è¿”å›: {
        "trend": "improving/stable/declining", 
        "suggestion": "å»ºè®®æ–‡æœ¬",
        "stats": {...}
    }
    """
    if not records or len(records) == 0:
        return {
            "trend": "no_data",
            "suggestion": "æš‚æ— è®­ç»ƒæ•°æ®ï¼Œå¼€å§‹æ‚¨çš„ç¬¬ä¸€æ¬¡è®­ç»ƒå§ï¼",
            "stats": {}
        }
    
    game_times = [r['gameTime'] for r in records]
    total_games = len(game_times)
    
    # åŸºç¡€ç»Ÿè®¡
    avg_time = sum(game_times) / total_games
    max_time = max(game_times)
    min_time = min(game_times)
    
    stats = {
        "totalGames": total_games,
        "avgTime": round(avg_time, 1),
        "maxTime": max_time,
        "minTime": min_time
    }
    
    # æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿
    if total_games < 3:
        return {
            "trend": "insufficient",
            "suggestion": f"å·²å®Œæˆ{total_games}æ¬¡è®­ç»ƒï¼Œç»§ç»­åŠ æ²¹ï¼å»ºè®®è‡³å°‘å®Œæˆ5æ¬¡è®­ç»ƒåæŸ¥çœ‹è¶‹åŠ¿åˆ†æã€‚",
            "stats": stats
        }
    
    # è®¡ç®—è¶‹åŠ¿ï¼šä½¿ç”¨çº¿æ€§å›å½’æ–œç‡
    # y = game_time, x = game_index
    n = len(game_times)
    x = list(range(n))
    y = game_times
    
    # è®¡ç®—çº¿æ€§å›å½’æ–œç‡
    x_mean = sum(x) / n
    y_mean = sum(y) / n
    
    numerator = sum((x[i] - x_mean) * (y[i] - y_mean) for i in range(n))
    denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
    
    slope = numerator / denominator if denominator != 0 else 0
    
    # è®¡ç®—æœ€è¿‘5æ¬¡ä¸æ•´ä½“å¹³å‡çš„å¯¹æ¯”
    recent_count = min(5, total_games)
    recent_avg = sum(game_times[-recent_count:]) / recent_count
    improvement_rate = ((recent_avg - avg_time) / avg_time * 100) if avg_time > 0 else 0
    
    # è®¡ç®—ç¨³å®šæ€§ï¼ˆå˜å¼‚ç³»æ•°ï¼‰
    std_dev = (sum((t - avg_time) ** 2 for t in game_times) / total_games) ** 0.5
    cv = (std_dev / avg_time * 100) if avg_time > 0 else 0  # å˜å¼‚ç³»æ•°
    
    # åˆ¤æ–­è¶‹åŠ¿
    trend = "stable"
    suggestion = ""
    
    # æ–œç‡é˜ˆå€¼ï¼šæ¯æ¬¡æå‡è¶…è¿‡1ç§’ä¸ºæ˜æ˜¾è¿›æ­¥
    if slope > 1.0 and improvement_rate > 10:
        trend = "improving"
        if cv < 20:
            suggestion = f"ğŸ‰ å¤ªæ£’äº†ï¼æ‚¨çš„ä¸“æ³¨æ—¶é—´æŒç»­æå‡ï¼Œæœ€è¿‘è¡¨ç°æ¯”å¹³å‡æ°´å¹³é«˜{abs(improvement_rate):.1f}%ï¼è€Œä¸”è¡¨ç°å¾ˆç¨³å®šã€‚ç»§ç»­ä¿æŒè¿™ä¸ªèŠ‚å¥ï¼Œå»ºè®®æ¯å¤©è®­ç»ƒ1-2æ¬¡ã€‚"
        else:
            suggestion = f"ğŸ“ˆ å¾ˆå¥½ï¼æ‚¨çš„ä¸“æ³¨æ—¶é—´åœ¨æå‡ï¼Œæœ€è¿‘è¡¨ç°æ¯”å¹³å‡æ°´å¹³é«˜{abs(improvement_rate):.1f}%ã€‚ä¸è¿‡æ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®ä¿æŒè§„å¾‹çš„è®­ç»ƒæ—¶é—´ï¼Œé¿å…è¿‡åº¦ç–²åŠ³ã€‚"
    
    elif slope < -1.0 and improvement_rate < -10:
        trend = "declining"
        if total_games < 10:
            suggestion = f"ğŸ’ª å‰æœŸé€‚åº”å¾ˆæ­£å¸¸ï¼æ‚¨çš„ä¸“æ³¨æ—¶é—´æš‚æ—¶ä¸‹é™äº†{abs(improvement_rate):.1f}%ï¼Œä½†è¿™å¯èƒ½æ˜¯åœ¨å¯»æ‰¾æœ€é€‚åˆè‡ªå·±çš„èŠ‚å¥ã€‚å»ºè®®ï¼šâ‘ ç¡®ä¿è®­ç»ƒç¯å¢ƒå®‰é™ â‘¡æ¯æ¬¡è®­ç»ƒå‰åšæ·±å‘¼å¸æ”¾æ¾ â‘¢å°è¯•ä¸åŒæ—¶æ®µæ‰¾åˆ°æœ€ä½³çŠ¶æ€ã€‚"
        else:
            suggestion = f"âš ï¸ æ³¨æ„ï¼šæœ€è¿‘çš„ä¸“æ³¨æ—¶é—´ä¸‹é™äº†{abs(improvement_rate):.1f}%ã€‚å¯èƒ½åŸå› ï¼šâ‘ è®­ç»ƒç–²åŠ³ â‘¡æ³¨æ„åŠ›åˆ†æ•£ â‘¢å‹åŠ›è¿‡å¤§ã€‚å»ºè®®ï¼šâ‘ é€‚å½“ä¼‘æ¯1-2å¤© â‘¡è°ƒæ•´è®­ç»ƒæ—¶é—´åˆ°ç²¾åŠ›å……æ²›æ—¶æ®µ â‘¢å‡å°‘è®­ç»ƒéš¾åº¦ï¼Œé‡å»ºä¿¡å¿ƒã€‚"
    
    else:
        # ç¨³å®šçŠ¶æ€
        if cv < 15:
            if avg_time > 60:
                suggestion = f"âœ¨ éå¸¸å¥½ï¼æ‚¨çš„ä¸“æ³¨æ—¶é—´ç¨³å®šåœ¨{avg_time:.0f}ç§’å·¦å³ï¼Œè¡¨ç°å¾ˆç¨³å®šï¼ˆæ³¢åŠ¨å°äº15%ï¼‰ã€‚æ‚¨å·²ç»å»ºç«‹äº†è‰¯å¥½çš„ä¸“æ³¨åŠ›åŸºç¡€ã€‚ä¸‹ä¸€æ­¥å»ºè®®ï¼šâ‘ å°è¯•å¢åŠ éš¾åº¦ â‘¡å»¶é•¿è®­ç»ƒæ—¶é—´ â‘¢è®¾å®šæ–°çš„æŒ‘æˆ˜ç›®æ ‡ã€‚"
            else:
                suggestion = f"ğŸ“Š è¡¨ç°ç¨³å®šï¼Œå¹³å‡ä¸“æ³¨æ—¶é—´{avg_time:.0f}ç§’ï¼Œæ³¢åŠ¨è¾ƒå°ã€‚ç»§ç»­ä¿æŒè§„å¾‹è®­ç»ƒï¼Œæ‚¨çš„ä¸“æ³¨åŠ›æ­£åœ¨ç¨³æ­¥æå‡ã€‚å»ºè®®æ¯æ¬¡è®­ç»ƒåè®°å½•æ„Ÿå—ï¼Œæ‰¾åˆ°æœ€ä½³çŠ¶æ€ã€‚"
        else:
            suggestion = f"ğŸ“Š æ‚¨çš„å¹³å‡ä¸“æ³¨æ—¶é—´æ˜¯{avg_time:.0f}ç§’ï¼Œä½†æ³¢åŠ¨è¾ƒå¤§ï¼ˆå˜å¼‚ç³»æ•°{cv:.1f}%ï¼‰ã€‚å»ºè®®ï¼šâ‘ å›ºå®šæ¯å¤©è®­ç»ƒæ—¶é—´ â‘¡ä¿æŒè®­ç»ƒç¯å¢ƒä¸€è‡´ â‘¢è®­ç»ƒå‰åš5åˆ†é’Ÿå†¥æƒ³æ”¾æ¾ â‘£é¿å…åœ¨ç–²åŠ³æˆ–æƒ…ç»ªä¸ä½³æ—¶è®­ç»ƒã€‚"
    
    # æ·»åŠ é€šç”¨å»ºè®®
    if total_games >= 20:
        if max_time > avg_time * 1.5:
            suggestion += f"\n\nğŸ’¡ æ‚¨çš„æœ€ä½³è®°å½•æ˜¯{max_time}ç§’ï¼Œè¯´æ˜æ‚¨æœ‰å¾ˆå¤§æ½œåŠ›ã€‚è¯•ç€å›å¿†é‚£æ¬¡çš„çŠ¶æ€å’Œæ¡ä»¶ï¼Œå¤åˆ¶æˆåŠŸç»éªŒï¼"
    
    if total_games >= 30:
        suggestion += f"\n\nğŸ† å·²å®Œæˆ{total_games}æ¬¡è®­ç»ƒï¼Œæ‚¨çš„åšæŒéå¸¸å€¼å¾—ç§°èµï¼é•¿æœŸè®­ç»ƒå¯¹ADHDæ”¹å–„æ•ˆæœæ˜¾è‘—ï¼Œå»ºè®®ç»§ç»­ä¿æŒã€‚"
    
    stats.update({
        "slope": round(slope, 2),
        "improvementRate": round(improvement_rate, 1),
        "stability": round(100 - cv, 1),  # ç¨³å®šæ€§ç™¾åˆ†æ¯”
        "recentAvg": round(recent_avg, 1)
    })
    
    return {
        "trend": trend,
        "suggestion": suggestion,
        "stats": stats
    }

@app.route('/getGameRecords', methods=['POST'])
def get_game_records():
    """
    è·å–æ¸¸æˆæ—¶é•¿è®°å½•
    è¯·æ±‚å‚æ•°: { "userId": "ç”¨æˆ·openid", "date": "YYYYMMDD" (å¯é€‰,ä¸æä¾›åˆ™è¿”å›æ‰€æœ‰è®°å½•) }
    è¿”å›: { "success": bool, "records": [{"date": "æ—¥æœŸ", "time": "æ—¶é—´", "gameTime": æ—¶é•¿}], "error": "é”™è¯¯ä¿¡æ¯" }
    """
    try:
        data = request.json
        user_id = data.get('userId')
        target_date = data.get('date')  # å¯é€‰å‚æ•°

        if not user_id:
            return jsonify({"success": False, "error": "userId is required"}), 400

        # æ¸¸æˆè®°å½•ç›®å½•è·¯å¾„
        records_dir = os.path.join('data', user_id, 'game_records')

        if not os.path.exists(records_dir):
            return jsonify({"success": True, "records": []})

        records = []

        # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œåªè¯»å–è¯¥æ—¥æœŸçš„æ–‡ä»¶
        if target_date:
            try:
                datetime.datetime.strptime(target_date, "%Y%m%d")
            except ValueError:
                return jsonify({"success": False, "error": "Invalid date format (should be YYYYMMDD)"}), 400

            record_file = os.path.join(records_dir, f"{target_date}.txt")
            if os.path.exists(record_file):
                with open(record_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if ',' in line:
                            parts = line.split(',')
                            try:
                                record = {
                                    "timestamp": parts[0],
                                    "gameTime": int(parts[1])
                                }
                                # å…¼å®¹æ—§æ ¼å¼ï¼ˆæ— éš¾åº¦ä¿¡æ¯ï¼‰å’Œæ–°æ ¼å¼ï¼ˆæœ‰éš¾åº¦ä¿¡æ¯ï¼‰
                                if len(parts) >= 3:
                                    record["difficulty"] = parts[2]
                                else:
                                    record["difficulty"] = "normal"  # é»˜è®¤ä¸ºæ™®é€šéš¾åº¦
                                records.append(record)
                            except (ValueError, IndexError):
                                continue
        else:
            # è¯»å–æ‰€æœ‰æ—¥æœŸçš„è®°å½•æ–‡ä»¶
            for filename in sorted(os.listdir(records_dir)):
                if filename.endswith('.txt'):
                    record_file = os.path.join(records_dir, filename)
                    with open(record_file, 'r', encoding='utf-8') as f:
                        for line in f:
                            line = line.strip()
                            if ',' in line:
                                parts = line.split(',')
                                try:
                                    record = {
                                        "timestamp": parts[0],
                                        "gameTime": int(parts[1])
                                    }
                                    # å…¼å®¹æ—§æ ¼å¼ï¼ˆæ— éš¾åº¦ä¿¡æ¯ï¼‰å’Œæ–°æ ¼å¼ï¼ˆæœ‰éš¾åº¦ä¿¡æ¯ï¼‰
                                    if len(parts) >= 3:
                                        record["difficulty"] = parts[2]
                                    else:
                                        record["difficulty"] = "normal"  # é»˜è®¤ä¸ºæ™®é€šéš¾åº¦
                                    records.append(record)
                                except (ValueError, IndexError):
                                    continue

        # æŒ‰æ—¶é—´æˆ³æ’åº
        records.sort(key=lambda x: x['timestamp'])

        # è®¡ç®—è¶‹åŠ¿åˆ†æå’Œå»ºè®®
        analysis = analyze_training_trend(records)

        return jsonify({
            "success": True,
            "records": records,
            "analysis": analysis
        })

    except Exception as e:
        print(f"[è·å–æ¸¸æˆè®°å½•é”™è¯¯] {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/saveSchulteRecord', methods=['POST'])
def save_schulte_record():
    """
    ä¿å­˜èˆ’å°”ç‰¹æ–¹æ ¼è®­ç»ƒè®°å½•
    """
    try:
        data = request.get_json()
        user_id = data.get('userId', 'user001')
        difficulty = data.get('difficulty', '5x5')  # 5x5, 6x6, 7x7
        time = data.get('time', 0)  # å®Œæˆç”¨æ—¶ï¼ˆç§’ï¼‰
        
        if time <= 0:
            return jsonify({"success": False, "error": "æ— æ•ˆçš„ç”¨æ—¶"}), 400
        
        # èˆ’å°”ç‰¹æ–¹æ ¼è®°å½•ç›®å½•è·¯å¾„ï¼ˆæŒ‰ç”¨æˆ·å’Œéš¾åº¦åˆ†ç±»ï¼‰
        records_dir = os.path.join('data', user_id, 'schulte', difficulty)
        os.makedirs(records_dir, exist_ok=True)
        
        # è·å–å½“å‰æ—¥æœŸ
        current_time = datetime.datetime.now()
        date_str = current_time.strftime("%Y-%m-%d")
        timestamp = current_time.strftime("%Y-%m-%d %H:%M:%S")
        
        # è®°å½•æ–‡ä»¶è·¯å¾„ï¼ˆæŒ‰æ—¥æœŸå‘½åï¼‰
        record_file = os.path.join(records_dir, f"{date_str}.txt")
        
        # è¿½åŠ è®°å½•ï¼ˆæ ¼å¼ï¼šæ—¶é—´æˆ³,ç”¨æ—¶ï¼‰
        with open(record_file, 'a', encoding='utf-8') as f:
            f.write(f"{timestamp},{time}\n")
        
        print(f"[èˆ’å°”ç‰¹è®°å½•] ç”¨æˆ· {user_id} éš¾åº¦ {difficulty} ç”¨æ—¶ {time}ç§’ å·²ä¿å­˜")
        return jsonify({"success": True})
        
    except Exception as e:
        print(f"[èˆ’å°”ç‰¹è®°å½•é”™è¯¯] {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/getSchulteRecords', methods=['GET'])
def get_schulte_records():
    """
    è·å–èˆ’å°”ç‰¹æ–¹æ ¼è®­ç»ƒè®°å½•
    """
    try:
        user_id = request.args.get('userId', 'user001')
        difficulty = request.args.get('difficulty', '5x5')
        
        # èˆ’å°”ç‰¹æ–¹æ ¼è®°å½•ç›®å½•è·¯å¾„
        records_dir = os.path.join('data', user_id, 'schulte', difficulty)
        
        if not os.path.exists(records_dir):
            return jsonify({
                "success": True,
                "records": [],
                "stats": {
                    "bestTime": 0,
                    "avgTime": 0,
                    "totalGames": 0
                }
            })
        
        # è¯»å–æ‰€æœ‰è®°å½•æ–‡ä»¶
        all_records = []
        for filename in os.listdir(records_dir):
            if filename.endswith('.txt'):
                file_path = os.path.join(records_dir, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        for line in f:
                            line = line.strip()
                            if line:
                                parts = line.split(',')
                                if len(parts) >= 2:
                                    timestamp = parts[0]
                                    time_value = float(parts[1])
                                    all_records.append({
                                        "timestamp": timestamp,
                                        "time": time_value,
                                        "date": timestamp.split()[0]
                                    })
                except Exception as e:
                    print(f"[è¯»å–æ–‡ä»¶é”™è¯¯] {filename}: {e}")
                    continue
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        all_records.sort(key=lambda x: x['timestamp'], reverse=True)
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        stats = {
            "bestTime": 0,
            "avgTime": 0,
            "totalGames": 0
        }
        
        if all_records:
            times = [r['time'] for r in all_records]
            stats['bestTime'] = min(times)
            stats['avgTime'] = sum(times) / len(times)
            stats['totalGames'] = len(times)
        
        return jsonify({
            "success": True,
            "records": all_records[:50],  # è¿”å›æœ€è¿‘50æ¡è®°å½•
            "stats": stats
        })

    except Exception as e:
        print(f"[è·å–èˆ’å°”ç‰¹è®°å½•é”™è¯¯] {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

def collect_user_training_data(user_id):
    """
    æ”¶é›†ç”¨æˆ·æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
    1. èº²é¿æ¸¸æˆè®°å½•ï¼ˆè®­ç»ƒé¢‘ç‡ã€æˆç»©ã€æ—¶é—´æ®µï¼‰
    2. èˆ’å°”ç‰¹æ–¹æ ¼è®°å½•ï¼ˆä¸åŒéš¾åº¦ï¼‰
    3. ç¦»çº¿å®éªŒæ ‡å®šæ•°æ®
    """
    training_data = {
        "game_records": [],
        "schulte_records": {},
        "calibration_data": None,
        "summary": {}
    }
    
    # 1. æ”¶é›†èº²é¿æ¸¸æˆè®°å½•
    game_records_dir = os.path.join('data', user_id, 'game_records')
    if os.path.exists(game_records_dir):
        game_records = []
        for filename in sorted(os.listdir(game_records_dir)):
            if filename.endswith('.txt'):
                record_file = os.path.join(game_records_dir, filename)
                with open(record_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if ',' in line:
                            parts = line.split(',')
                            try:
                                timestamp = parts[0]
                                game_time = int(parts[1])
                                difficulty = parts[2] if len(parts) >= 3 else "normal"
                                
                                # è§£ææ—¶é—´æ®µ
                                hour = int(timestamp.split()[1].split(':')[0])
                                time_period = "æ—©æ™¨" if 6 <= hour < 12 else "ä¸‹åˆ" if 12 <= hour < 18 else "æ™šä¸Š"
                                
                                game_records.append({
                                    "timestamp": timestamp,
                                    "gameTime": game_time,
                                    "difficulty": difficulty,
                                    "hour": hour,
                                    "timePeriod": time_period
                                })
                            except (ValueError, IndexError):
                                continue
        training_data["game_records"] = game_records
    
    # 2. æ”¶é›†èˆ’å°”ç‰¹æ–¹æ ¼è®°å½•
    schulte_base_dir = os.path.join('data', user_id, 'schulte')
    if os.path.exists(schulte_base_dir):
        for difficulty in ['5x5', '6x6', '7x7']:
            difficulty_dir = os.path.join(schulte_base_dir, difficulty)
            if os.path.exists(difficulty_dir):
                records = []
                for filename in os.listdir(difficulty_dir):
                    if filename.endswith('.txt'):
                        file_path = os.path.join(difficulty_dir, filename)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                for line in f:
                                    line = line.strip()
                                    if line:
                                        parts = line.split(',')
                                        if len(parts) >= 2:
                                            timestamp = parts[0]
                                            time_value = float(parts[1])
                                            
                                            # è§£ææ—¶é—´æ®µ
                                            hour = int(timestamp.split()[1].split(':')[0])
                                            time_period = "æ—©æ™¨" if 6 <= hour < 12 else "ä¸‹åˆ" if 12 <= hour < 18 else "æ™šä¸Š"
                                            
                                            records.append({
                                                "timestamp": timestamp,
                                                "time": time_value,
                                                "hour": hour,
                                                "timePeriod": time_period
                                            })
                        except Exception as e:
                            continue
                training_data["schulte_records"][difficulty] = records
    
    # 3. æ”¶é›†ç¦»çº¿æ ‡å®šæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    calibration_file = os.path.join('data', user_id, 'eeg_data', 'calibration_result.json')
    if os.path.exists(calibration_file):
        try:
            with open(calibration_file, 'r', encoding='utf-8') as f:
                training_data["calibration_data"] = json.load(f)
        except:
            pass
    
    # 4. ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
    summary = {}
    
    # èº²é¿æ¸¸æˆç»Ÿè®¡
    if game_records:
        game_times = [r['gameTime'] for r in game_records]
        time_periods = {}
        for r in game_records:
            period = r['timePeriod']
            time_periods[period] = time_periods.get(period, []) + [r['gameTime']]
        
        summary['game'] = {
            "total_count": len(game_records),
            "avg_time": sum(game_times) / len(game_times),
            "best_time": max(game_times),
            "worst_time": min(game_times),
            "by_time_period": {
                period: {
                    "count": len(times),
                    "avg": sum(times) / len(times)
                } for period, times in time_periods.items()
            },
            "recent_7_days": len([r for r in game_records if (datetime.datetime.now() - datetime.datetime.strptime(r['timestamp'], "%Y-%m-%d %H:%M:%S")).days <= 7]),
            "training_days": len(set(r['timestamp'].split()[0] for r in game_records))
        }
    
    # èˆ’å°”ç‰¹æ–¹æ ¼ç»Ÿè®¡
    schulte_summary = {}
    for difficulty, records in training_data["schulte_records"].items():
        if records:
            times = [r['time'] for r in records]
            schulte_summary[difficulty] = {
                "total_count": len(records),
                "best_time": min(times),
                "avg_time": sum(times) / len(times),
                "recent_7_days": len([r for r in records if (datetime.datetime.now() - datetime.datetime.strptime(r['timestamp'], "%Y-%m-%d %H:%M:%S")).days <= 7])
            }
    if schulte_summary:
        summary['schulte'] = schulte_summary
    
    training_data["summary"] = summary
    return training_data

def generate_ai_advice(training_data):
    """
    ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼å¤§æ¨¡å‹ç”Ÿæˆè®­ç»ƒå»ºè®®
    """
    try:
        # æ„å»ºprompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ADHDï¼ˆæ³¨æ„åŠ›ç¼ºé™·å¤šåŠ¨éšœç¢ï¼‰è®­ç»ƒæŒ‡å¯¼ä¸“å®¶ï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·çš„è®­ç»ƒæ•°æ®ç»™å‡ºé’ˆå¯¹æ€§çš„å»ºè®®ã€‚

ç”¨æˆ·è®­ç»ƒæ•°æ®æ‘˜è¦ï¼š

ã€å¡”é˜²å°æ¸¸æˆè®­ç»ƒã€‘
"""
        if 'game' in training_data['summary']:
            game_data = training_data['summary']['game']
            prompt += f"- æ€»è®­ç»ƒæ¬¡æ•°ï¼š{game_data['total_count']}æ¬¡\n"
            prompt += f"- å¹³å‡ç”Ÿå­˜æ—¶é—´ï¼š{game_data['avg_time']:.1f}ç§’\n"
            prompt += f"- æœ€é•¿ç”Ÿå­˜æ—¶é—´ï¼š{game_data['best_time']}ç§’\n"
            prompt += f"- æœ€çŸ­ç”Ÿå­˜æ—¶é—´ï¼š{game_data['worst_time']}ç§’\n"
            prompt += f"- è®­ç»ƒå¤©æ•°ï¼š{game_data['training_days']}å¤©\n"
            prompt += f"- è¿‘7å¤©è®­ç»ƒæ¬¡æ•°ï¼š{game_data['recent_7_days']}æ¬¡\n"
            
            if 'by_time_period' in game_data:
                prompt += "\nä¸åŒæ—¶æ®µè®­ç»ƒè¡¨ç°ï¼š\n"
                for period, stats in game_data['by_time_period'].items():
                    prompt += f"  â€¢ {period}ï¼š{stats['count']}æ¬¡è®­ç»ƒï¼Œå¹³å‡ç”Ÿå­˜{stats['avg']:.1f}ç§’\n"
        else:
            prompt += "- æš‚æ— å¡”é˜²æ¸¸æˆè®­ç»ƒè®°å½•\n"
        
        prompt += "\nã€èˆ’å°”ç‰¹æ–¹æ ¼è®­ç»ƒã€‘\n"
        if 'schulte' in training_data['summary']:
            for difficulty, stats in training_data['summary']['schulte'].items():
                prompt += f"- {difficulty}éš¾åº¦ï¼š{stats['total_count']}æ¬¡è®­ç»ƒï¼Œæœ€ä½³{stats['best_time']:.1f}ç§’ï¼Œå¹³å‡{stats['avg_time']:.1f}ç§’\n"
        else:
            prompt += "- æš‚æ— èˆ’å°”ç‰¹æ–¹æ ¼è®­ç»ƒè®°å½•\n"
        
        prompt += """

è¯·åŸºäºä»¥ä¸Šæ•°æ®ï¼Œä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦ç»™å‡ºå»ºè®®ï¼š
1. **è®­ç»ƒé¢‘ç‡**ï¼šè¯„ä¼°å½“å‰è®­ç»ƒé¢‘ç‡æ˜¯å¦åˆç†ï¼Œæ˜¯å¦éœ€è¦è°ƒæ•´
2. **è®­ç»ƒæ•ˆæœ**ï¼šåˆ†æè®­ç»ƒæˆç»©çš„å˜åŒ–è¶‹åŠ¿ï¼ˆå¡”é˜²æ¸¸æˆç”Ÿå­˜æ—¶é—´æ˜¯å¦æå‡ï¼Œèˆ’å°”ç‰¹æ–¹æ ¼å®Œæˆæ—¶é—´æ˜¯å¦ç¼©çŸ­ï¼‰
3. **è®­ç»ƒæ—¶æ®µ**ï¼šæ ¹æ®ä¸åŒæ—¶æ®µçš„è¡¨ç°ï¼Œå»ºè®®æœ€ä½³è®­ç»ƒæ—¶é—´
4. **è®­ç»ƒéš¾åº¦**ï¼šæ˜¯å¦éœ€è¦è°ƒæ•´éš¾åº¦ä»¥è·å¾—æ›´å¥½çš„è®­ç»ƒæ•ˆæœ
5. **ä¸ªæ€§åŒ–å»ºè®®**ï¼šç»“åˆç”¨æˆ·çš„å…·ä½“æƒ…å†µï¼Œç»™å‡º3-5æ¡å®ç”¨çš„è®­ç»ƒå»ºè®®

è¯·ç”¨æ¸©æš–ã€é¼“åŠ±çš„è¯­æ°”ï¼Œç»™å‡º200å­—å·¦å³çš„ç»¼åˆå»ºè®®ã€‚ä½¿ç”¨emojiè®©å»ºè®®æ›´ç”ŸåŠ¨å‹å¥½ã€‚"""

        # è°ƒç”¨å¤§æ¨¡å‹
        try:
            # å‚è€ƒGDScript working exampleï¼Œä½¿ç”¨requestsç›´æ¥è°ƒç”¨APIï¼Œé¿å…SDKå…¼å®¹æ€§é—®é¢˜
            api_key = os.getenv("DASHSCOPE_API_KEY", "sk-341c8f4ad671494c84d12201dc2737cf")
            url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            payload = {
                "model": "qwen-flash",
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€æ¸©æš–çš„ADHDè®­ç»ƒæŒ‡å¯¼ä¸“å®¶ï¼Œæ“…é•¿åˆ†æç”¨æˆ·æ•°æ®å¹¶ç»™å‡ºä¸ªæ€§åŒ–å»ºè®®ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.7,
                "max_tokens": 800
            }
            
            # å¢åŠ è¶…æ—¶è®¾ç½®
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    advice = result["choices"][0]["message"]["content"]
                    return advice
                else:
                    print(f"[AIå»ºè®®ç”Ÿæˆé”™è¯¯] å“åº”æ ¼å¼å¼‚å¸¸: {result}")
            else:
                print(f"[AIå»ºè®®ç”Ÿæˆé”™è¯¯] APIè¿”å›é”™è¯¯: {response.status_code} - {response.text}")
                
            return "æš‚æ—¶æ— æ³•ç”ŸæˆAIå»ºè®®ï¼Œè¯·ç¨åå†è¯•ã€‚ç»§ç»­ä¿æŒè§„å¾‹è®­ç»ƒï¼Œæ‚¨çš„åšæŒä¸€å®šä¼šæœ‰å›æŠ¥ï¼ğŸ’ª"
            
        except Exception as e:
            print(f"[AIå»ºè®®ç”Ÿæˆé”™è¯¯] {e}")
            print("è¯·å‚è€ƒæ–‡æ¡£ï¼šhttps://help.aliyun.com/zh/model-studio/developer-reference/error-code")
            return "æš‚æ—¶æ— æ³•ç”ŸæˆAIå»ºè®®ï¼Œè¯·ç¨åå†è¯•ã€‚ç»§ç»­ä¿æŒè§„å¾‹è®­ç»ƒï¼Œæ‚¨çš„åšæŒä¸€å®šä¼šæœ‰å›æŠ¥ï¼ğŸ’ª"

    except Exception as e:
        print(f"[å…¨å±€AIå»ºè®®é”™è¯¯] {e}")
        return "æš‚æ—¶æ— æ³•ç”ŸæˆAIå»ºè®®ï¼Œè¯·ç¨åå†è¯•ã€‚"

@app.route('/getAIAdvice', methods=['POST'])
def get_ai_advice():
    """
    è·å–AIç”Ÿæˆçš„è®­ç»ƒå»ºè®®
    """
    try:
        data = request.get_json()
        user_id = data.get('userId')
        
        if not user_id:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘ç”¨æˆ·ID"
            }), 400
        
        # æ”¶é›†ç”¨æˆ·è®­ç»ƒæ•°æ®
        training_data = collect_user_training_data(user_id)
        
        # ç”ŸæˆAIå»ºè®®
        advice = generate_ai_advice(training_data)
        
        return jsonify({
            "success": True,
            "advice": advice,
            "summary": training_data['summary']
        })
        
    except Exception as e:
        print(f"[è·å–AIå»ºè®®é”™è¯¯] {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

if __name__ == '__main__':
    os.makedirs('data', exist_ok=True)
    flask_thread = threading.Thread(target=run_flask, daemon=True)
    flask_thread.start()

    fig, ax = plt.subplots()
    raw_line, = ax.plot([], [], label='Raw Data')
    processed_line, = ax.plot([], [], label='Processed Data')
    ax.legend()
    ax.set_title("Processing Window (6s) with 0.5s Overlap")

    ani = FuncAnimation(
        fig,
        update_plot,
        interval=50,
    )

    plt.show()
